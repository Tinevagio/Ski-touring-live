import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Configuration visualisation
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.float_format', '{:.2f}'.format)

print("ðŸŽ¿ ANALYSE EXPLORATOIRE - DATASET SKITOUR")
print("=" * 80)

# === 1. CHARGEMENT ET APERÃ‡U ===
print("\nðŸ“‚ 1. CHARGEMENT DES DONNÃ‰ES")
print("-" * 80)

df = pd.read_csv('skitour_ml_dataset_openmeteo.csv')

print(f"âœ… Dataset chargÃ©: {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
print(f"\nPremiÃ¨res lignes:")
print(df.head(3))

print(f"\nðŸ“‹ Types de donnÃ©es:")
print(df.dtypes.value_counts())

print(f"\nðŸ’¾ MÃ©moire utilisÃ©e: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# === 2. DONNÃ‰ES MANQUANTES ===
print("\n" + "=" * 80)
print("ðŸ•³ï¸  2. ANALYSE DES DONNÃ‰ES MANQUANTES")
print("-" * 80)

missing = pd.DataFrame({
    'Colonne': df.columns,
    'Manquants': df.isnull().sum(),
    'Pourcentage': (df.isnull().sum() / len(df) * 100).round(2)
})
missing = missing[missing['Manquants'] > 0].sort_values('Pourcentage', ascending=False)

if len(missing) > 0:
    print(f"\nâš ï¸  {len(missing)} colonnes avec donnÃ©es manquantes:\n")
    print(missing.to_string(index=False))
    
    # Visualisation
    plt.figure(figsize=(12, 6))
    plt.barh(missing['Colonne'], missing['Pourcentage'], color='coral')
    plt.xlabel('Pourcentage de valeurs manquantes (%)')
    plt.title('DonnÃ©es manquantes par colonne')
    plt.tight_layout()
    plt.savefig('eda_missing_data.png', dpi=300, bbox_inches='tight')
    print("\nðŸ“Š Graphique sauvegardÃ©: eda_missing_data.png")
else:
    print("\nâœ… Aucune donnÃ©e manquante !")

# === 3. VARIABLE CIBLE (SKIABILITÃ‰) ===
print("\n" + "=" * 80)
print("ðŸŽ¯ 3. ANALYSE DE LA VARIABLE CIBLE: SKIABILITÃ‰")
print("-" * 80)

print("\nðŸ“Š Distribution skiabilite_score:")
print(df['skiabilite_score'].value_counts().sort_index())

print("\nðŸ“Š Distribution skiabilite_label:")
skiab_dist = df['skiabilite_label'].value_counts()
print(skiab_dist)
print(f"\nProportion (%): ")
print((skiab_dist / len(df) * 100).round(2))

# VÃ©rifier dÃ©sÃ©quilibre
max_class = skiab_dist.max()
min_class = skiab_dist.min()
imbalance_ratio = max_class / min_class if min_class > 0 else np.inf
print(f"\nâš–ï¸  Ratio dÃ©sÃ©quilibre: {imbalance_ratio:.2f}:1")
if imbalance_ratio > 3:
    print("âš ï¸  ATTENTION: Classes trÃ¨s dÃ©sÃ©quilibrÃ©es ! PrÃ©voir rÃ©Ã©quilibrage (SMOTE, weights)")

# Visualisation
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Score numÃ©rique
df['skiabilite_score'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')
axes[0].set_title('Distribution SkiabilitÃ© (Score 0-4)')
axes[0].set_xlabel('Score')
axes[0].set_ylabel('Nombre de sorties')
axes[0].grid(axis='y', alpha=0.3)

# Labels
df['skiabilite_label'].value_counts().plot(kind='bar', ax=axes[1], color='lightcoral')
axes[1].set_title('Distribution SkiabilitÃ© (Labels)')
axes[1].set_xlabel('QualitÃ©')
axes[1].set_ylabel('Nombre de sorties')
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('eda_target_distribution.png', dpi=300, bbox_inches='tight')
print("\nðŸ“Š Graphique sauvegardÃ©: eda_target_distribution.png")

# === 4. STATISTIQUES DESCRIPTIVES ===
print("\n" + "=" * 80)
print("ðŸ“ˆ 4. STATISTIQUES DESCRIPTIVES (Variables numÃ©riques)")
print("-" * 80)

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
# Exclure colonnes ID et dates
numeric_cols = [col for col in numeric_cols if col not in ['id_sortie', 'date_unix', 'day_of_week']]

print(f"\n{len(numeric_cols)} variables numÃ©riques analysÃ©es\n")
print(df[numeric_cols].describe().T)

# DÃ©tection outliers (IQR method)
print("\nðŸ” DÃ©tection des outliers (mÃ©thode IQR):")
outliers_summary = []

for col in numeric_cols:
    if df[col].notna().sum() > 0:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        n_outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
        pct_outliers = (n_outliers / df[col].notna().sum() * 100)
        
        if pct_outliers > 5:
            outliers_summary.append({
                'Colonne': col,
                'N_outliers': n_outliers,
                'Pourcentage': f"{pct_outliers:.1f}%"
            })

if outliers_summary:
    print("\nâš ï¸  Colonnes avec > 5% d'outliers:")
    print(pd.DataFrame(outliers_summary).to_string(index=False))
else:
    print("\nâœ… Pas d'outliers significatifs dÃ©tectÃ©s")

# === 5. CORRÃ‰LATIONS ===
print("\n" + "=" * 80)
print("ðŸ”— 5. ANALYSE DES CORRÃ‰LATIONS")
print("-" * 80)

# CorrÃ©lations avec la cible
target_corr = df[numeric_cols].corr()['skiabilite_score'].sort_values(ascending=False)
print("\nðŸ“Š Top 10 corrÃ©lations avec skiabilite_score:\n")
print(target_corr.head(10))

print("\nðŸ“Š Bottom 10 corrÃ©lations avec skiabilite_score:\n")
print(target_corr.tail(10))

# Matrice de corrÃ©lation complÃ¨te
plt.figure(figsize=(16, 14))
corr_matrix = df[numeric_cols].corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Masque triangulaire
sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', 
            center=0, vmin=-1, vmax=1, square=True, linewidths=0.5)
plt.title('Matrice de corrÃ©lation (triangle infÃ©rieur)')
plt.tight_layout()
plt.savefig('eda_correlation_matrix.png', dpi=300, bbox_inches='tight')
print("\nðŸ“Š Graphique sauvegardÃ©: eda_correlation_matrix.png")

# MulticolinÃ©aritÃ© forte
print("\nâš ï¸  Paires de variables fortement corrÃ©lÃ©es (|r| > 0.8):")
high_corr = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > 0.8:
            high_corr.append({
                'Variable 1': corr_matrix.columns[i],
                'Variable 2': corr_matrix.columns[j],
                'CorrÃ©lation': f"{corr_matrix.iloc[i, j]:.3f}"
            })

if high_corr:
    print(pd.DataFrame(high_corr).to_string(index=False))
    print("\nðŸ’¡ Conseil: Garder une seule variable par paire fortement corrÃ©lÃ©e")
else:
    print("âœ… Pas de multicolinÃ©aritÃ© forte dÃ©tectÃ©e")

# === 6. DISTRIBUTIONS DES FEATURES CLÃ‰S ===
print("\n" + "=" * 80)
print("ðŸ“Š 6. DISTRIBUTIONS DES FEATURES CLÃ‰S")
print("-" * 80)

# SÃ©lection features importantes
key_features = ['temp_max', 'snowfall_cm', 'wind_max_kmh', 'topo_slope_max_deg', 
                'summit_altitude_clean', 'denivele', 'temp_max_7d_avg', 'precipitation_mm']
key_features = [f for f in key_features if f in df.columns]

fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.flatten()

for idx, col in enumerate(key_features[:9]):
    if df[col].notna().sum() > 0:
        axes[idx].hist(df[col].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)
        axes[idx].set_title(f'{col}')
        axes[idx].set_ylabel('FrÃ©quence')
        axes[idx].grid(axis='y', alpha=0.3)
        
        # Ajouter stats
        mean_val = df[col].mean()
        median_val = df[col].median()
        axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Moy: {mean_val:.1f}')
        axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'MÃ©d: {median_val:.1f}')
        axes[idx].legend(fontsize=8)

plt.tight_layout()
plt.savefig('eda_distributions.png', dpi=300, bbox_inches='tight')
print("\nðŸ“Š Graphique sauvegardÃ©: eda_distributions.png")

# === 7. ANALYSE PAR CATÃ‰GORIES ===
print("\n" + "=" * 80)
print("ðŸ”ï¸  7. ANALYSE PAR CATÃ‰GORIES")
print("-" * 80)

# SkiabilitÃ© par saison
if 'season' in df.columns:
    print("\nðŸ“… SkiabilitÃ© moyenne par saison:")
    season_ski = df.groupby('season')['skiabilite_score'].agg(['mean', 'count', 'std'])
    print(season_ski.sort_values('mean', ascending=False))

# SkiabilitÃ© par massif (top 10)
if 'massif' in df.columns:
    print("\nðŸ—» Top 10 massifs avec meilleure skiabilitÃ©:")
    massif_ski = df.groupby('massif')['skiabilite_score'].agg(['mean', 'count']).sort_values('mean', ascending=False)
    massif_ski = massif_ski[massif_ski['count'] >= 3]  # Au moins 3 sorties
    print(massif_ski.head(10))

# SkiabilitÃ© par orientation
if 'topo_orientation' in df.columns:
    print("\nðŸ§­ SkiabilitÃ© moyenne par orientation:")
    orient_ski = df.groupby('topo_orientation')['skiabilite_score'].agg(['mean', 'count', 'std'])
    print(orient_ski.sort_values('mean', ascending=False))

# SkiabilitÃ© weekend vs semaine
if 'is_weekend' in df.columns:
    print("\nðŸ“† SkiabilitÃ© weekend vs semaine:")
    weekend_ski = df.groupby('is_weekend')['skiabilite_score'].agg(['mean', 'count'])
    weekend_ski.index = ['Semaine', 'Weekend']
    print(weekend_ski)

# Altitude
if 'altitude_category' in df.columns:
    print("\nâ›°ï¸  SkiabilitÃ© par tranche d'altitude:")
    alt_ski = df.groupby('altitude_category')['skiabilite_score'].agg(['mean', 'count'])
    print(alt_ski)

# === 8. BOXPLOTS PAR SKIABILITÃ‰ ===
print("\n" + "=" * 80)
print("ðŸ“¦ 8. BOXPLOTS DES FEATURES PAR NIVEAU DE SKIABILITÃ‰")
print("-" * 80)

key_features_box = ['temp_max', 'snowfall_cm', 'wind_max_kmh', 'topo_slope_max_deg']
key_features_box = [f for f in key_features_box if f in df.columns and df[f].notna().sum() > 10]

if key_features_box:
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()
    
    for idx, col in enumerate(key_features_box[:4]):
        df_plot = df[[col, 'skiabilite_label']].dropna()
        order = ['Mauvaise', 'MÃ©diocre', 'Correcte', 'Bonne', 'Excellente']
        order = [o for o in order if o in df_plot['skiabilite_label'].unique()]
        
        sns.boxplot(data=df_plot, x='skiabilite_label', y=col, ax=axes[idx], order=order)
        axes[idx].set_title(f'{col} par skiabilitÃ©')
        axes[idx].tick_params(axis='x', rotation=45)
        axes[idx].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('eda_boxplots_by_skiability.png', dpi=300, bbox_inches='tight')
    print("\nðŸ“Š Graphique sauvegardÃ©: eda_boxplots_by_skiability.png")

# === 9. RÃ‰SUMÃ‰ ET RECOMMANDATIONS ===
print("\n" + "=" * 80)
print("ðŸŽ¯ 9. RÃ‰SUMÃ‰ ET RECOMMANDATIONS")
print("=" * 80)

print("\nâœ… Analyse exploratoire terminÃ©e !")
print("\nðŸ“‹ FICHIERS GÃ‰NÃ‰RÃ‰S:")
print("   - eda_missing_data.png")
print("   - eda_target_distribution.png")
print("   - eda_correlation_matrix.png")
print("   - eda_distributions.png")
print("   - eda_boxplots_by_skiability.png")

print("\nðŸ’¡ PROCHAINES Ã‰TAPES RECOMMANDÃ‰ES:")
print("   1. Traiter les valeurs manquantes (imputation ou suppression)")
print("   2. GÃ©rer les outliers identifiÃ©s")
print("   3. RÃ©soudre la multicolinÃ©aritÃ© (Ã©liminer variables redondantes)")
print("   4. RÃ©Ã©quilibrer les classes si nÃ©cessaire (SMOTE, class_weight)")
print("   5. Feature engineering: crÃ©er des interactions et features dÃ©rivÃ©es")
print("   6. Encoder les variables catÃ©gorielles (massif, orientation, season)")
print("   7. Normaliser/standardiser les features numÃ©riques")
print("   8. Split train/test en prÃ©servant la distribution temporelle")

print("\n" + "=" * 80)